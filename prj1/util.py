
'''
   utility functions for processing terms

    shared by both indexing and query processing
'''



def isStopWord(word):
    ''' using the NLTK functions, return true/false'''

    # ToDo


def stemming(word):
    ''' return the stem, using a NLTK stemmer. check the project description for installing and using it'''

    # ToDo

def tokenize_doc(doc):
    """ Get each token (split on whitespace); lowercase each token """
    pass
    
def preprocess(doc):
    """ Gets all the docs in Cranfield dataset and preprocesses. Return list
        of preprocessed tokens in the document """
    pass

